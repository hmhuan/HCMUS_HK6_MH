{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vzi0erHpGywX",
    "toc-hr-collapsed": false
   },
   "source": [
    "# Hướng dẫn homework 5\n",
    "---\n",
    "- Bạn cần đọc đề bài trước khi đọc hướng dẫn.\n",
    "- Tốt nhất là nên tự làm trước rồi mới xem hướng dẫn, vì như vậy sẽ giúp rèn luyện khả năng giải quyết vấn đề từ điểm xuất phát là 0. Một vấn đề có thể có nhiều cách giải quyết, cách này có thể sẽ hiệu quả hơn cách kia; sau khi tự làm, bạn có thể xem hướng dẫn và so sánh cách làm của bạn với cách làm của hướng dẫn.\n",
    "- Không phải tất cả các câu đều sẽ có hướng dẫn (phần hướng dẫn chủ yếu tập trung vào các câu liên quan đến lập trình).\n",
    "- Nếu vẫn có thắc mắc gì khác thì bạn có thể post lên moodle.\n",
    "- Ở markdown cell của notebook, bạn có thể gõ công thức theo latex bằng cách bọc trong `$...$` (dạng inline), hoặc `$$...$$` (ví dụ, `$\\mu$` sẽ ra $\\mu$, `$\\nu$` sẽ ra $\\nu$, `$\\lambda$` sẽ ra $\\lambda$, `$\\epsilon$` sẽ ra $\\epsilon$, ...).\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jkPqn8NaGywZ"
   },
   "source": [
    "## Câu 1: Linear Regression Error\n",
    "Với setup như trong đề tài thì người ta đã chứng minh được:\n",
    "$$\\mathbb{E}_{\\mathcal{D}}[E_{in}(\\mathbf{w}_{lin})] = \\sigma^2\\left(1 - \\frac{d+1}{N}\\right)$$\n",
    "Đầu tiên, mình muốn giải thích một ít để bạn hiểu hơn về công thức này. Cái mà mô hình học thấy là các ouput $y$ tương ứng với các input $\\mathbf{x}$, và trong quá trình học mô hình cố gắng fit vào các output $y$ này. Nhưng output $y$ này bao gồm <font color=green>output \"sạch\" $\\mathbf{w}^{*T}\\mathbf{x}$ (là cái nên fit)</font> + <font color=red>nhiễu $\\epsilon$ có mean 0 và variance $\\sigma^2$ (nhiễu là cái không nên fit)</font>. Nếu bằng một cách nào đó, mô hình có thể fit vào output sạch thì $\\mathbf{w}_{lin}$ học được bằng với $\\mathbf{w^*}$ và $E_{in}\\approx E_{out} = \\sigma^2$ (độ lỗi đang nói tới ở đây là độ lỗi bình phương); đây là trường hợp tốt nhất. Theo công thức trên, ta thấy khi $N$ tăng thì $\\frac{d+1}{N}$ sẽ giảm về 0 và $E_{in}$ sẽ tăng lên và tiến tới $\\sigma^2$. Điều này là hợp lý vì khi $N$ nhỏ, mô hình có thể fit vào nhiễu và làm cho $E_{in}$ nhỏ hơn $\\sigma^2$ (tuy nhiên, đây không phải là điều tốt vì $E_{out}$ lớn hơn $\\sigma^2$; bạn có thể xem thêm hình vẽ ở slide 22, lecture 8 - bias variance). Khi $N$ tăng, mô hình sẽ dần thấy được sự thật: nhiễu là cái không thể fit (bạn hình dung khi một $\\mathbf{x}$ bắt đầu có nhiều $y$ thì mô hình chỉ có thể fit vào giá trị trung bình ở giữa); và bắt đầu fit vào cái nên fit là $\\mathbf{w}^{*T}\\mathbf{x}$. Lúc này, $E_{in}$ sẽ tăng lên và tiến tới $\\sigma^2$ (tuy nhiên, đây là điều tốt vì $E_{out}$ giảm và tiến tới $\\sigma^2$).\n",
    "\n",
    "Câu này hỏi là với $\\sigma=0.1$ và $d=8$ thì cần $N$ nhỏ nhất là bao nhiêu để $E_{in}$ (theo công thức ở trên) lớn hơn 0.008. Đây là bất phương trình theo $N$ và có thể giải được một cách dễ dàng."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9vbePR01xbBT"
   },
   "source": [
    "## Câu 2-3: Nonlinear Transforms\n",
    "**Câu 2:** \n",
    "\n",
    "Như đã học, nonlinear transform là một cách để tăng sức mạnh cho các mô hình tuyến tính, giúp các mô hình tuyến tính biểu diễn được các \"đường cong\" (bình thường thì chỉ biểu diễn được các \"đường thẳng\"). Phép nonlinear transform được cho trong đề bài là phép ánh xạ từ không gian $\\mathcal{X}$ hai chiều (chưa tính $x_0=1$) sang không gian $\\mathcal{Z}$ hai chiều (chưa tính $z_0=1$): $$\\Phi(1, x_1, x_2) = (1, x_1^2, x_2^2)$$\n",
    "Với phép transform này thì tập hypothesis của mô hình phân lớp tuyến tính (Perceptron) sẽ gồm các hypothesis có dạng: $$h(\\mathbf{x})=sign(\\tilde{w}_0 + \\tilde{w}_1 x_1^2 + \\tilde{w}_2 x_2^2)$$ \n",
    "Ví dụ, nếu $\\tilde{w}_0 = -4$, $\\tilde{w}_1=1$, $\\tilde{w}_2=1$ thì có thể dễ thấy $h(x)$ sẽ ứng với một đường tròn có bán kính bằng 2 trong không gian $\\mathcal{X}$, ngoài đường tròn thì $h(\\mathbf{x})=+1$ và trong đường tròn thì $h(\\mathbf{x})=-1$.\n",
    "\n",
    "Với các giá trị khác của $\\mathbf{\\tilde{w}}$ thì đường phân lớp của $h(x)$ có thể có các hình dạng khác, ví dụ như ở hình trong đề bài. Câu hỏi là với $\\mathbf{\\tilde{w}}$ như thế nào thì sẽ ra được hình trong đề bài?\n",
    "\n",
    "Một cách để làm bài này là dùng code để vẽ hình ứng các trường hợp của $\\mathbf{\\tilde{w}}$ và chọn ra trường hợp giống với hình cho trong đề bài. Một cách khác là lập luận như sau:\n",
    "- Ta có: $h(\\mathbf{x}) = sign(\\tilde{w}_0 + \\tilde{w}_1 x_1^2 + \\tilde{w}_2 x_2^2)$\n",
    "- Khi $x_1$ siêu âm hoặc siêu dương thì $x_1^2$ sẽ dương và rất lớn, và  $\\tilde{w}_1 x_1^2$ sẽ là đại lượng quyết định dấu của tổng trong công thức ở trên. Do $x_1^2$ dương nên $\\tilde{w}_1$ sẽ quyết định dấu của $\\tilde{w}_1 x_1^2$.\n",
    "- Tương tự với $x_2$.\n",
    "- Nhìn hình và suy luận ra dấu của $\\tilde{w}_1$ và $\\tilde{w}_2$.\n",
    "\n",
    "**Câu 3:** \n",
    "\n",
    "Bạn sử dụng công thức về $d_{VC}$ của mô hình phân lớp tuyến tính (Perceptron) trong không gian $\\mathcal{Z}$ ở slide 4, lecture 9 - the linear model II. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9cVt_qZ0Gywa"
   },
   "source": [
    "## Câu 4-7: Gradient Descent\n",
    "\n",
    "Mình nghĩ bạn có thể tự làm được các câu này."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p2WIVFXYUW5n",
    "toc-hr-collapsed": true
   },
   "source": [
    "## Câu 8-9: Logistic Regression\n",
    "\n",
    "Ở đây sẽ tập trung hướng dẫn về hàm quan trọng nhất là hàm huấn luyện (thuật toán học) của mô hình Logistic Regression. Ngoài ra, cũng sẽ nói về hàm dự đoán và hàm tính độ lỗi cross-entropy. Các hàm khác như phát sinh $f$ và phát sinh dữ liệu thì bạn có thể tham khảo trong file \"HwExample.ipynb\" ở bài tập 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1HIxzkhNUW5o"
   },
   "source": [
    "**Hàm huấn luyện Logistic Regression**\n",
    "\n",
    "<font color=blue>Input của hàm </font>\n",
    "- `X`: mảng Numpy, kích thước $N\\times(d+1)$ với $N$ là số lượng mẫu huấn luyện, $d$ là số chiều của véc-tơ input (chưa tính thành phần $x_0=1$). Mỗi dòng của `X` ứng với một véc-tơ input (đã có $x_0$).\n",
    "- `Y`: mảng Numpy, kích thước $N\\times1$. `Y` chứa các output đúng tương ứng với các véc-tơ input trong `X`.\n",
    "\n",
    "<font color=blue>Output của hàm</font>\n",
    "\n",
    "- `w`: mảng Numpy, kích thước $(d+1)\\times1$. `w` chính là véc-tơ trọng số của final hypothesis $g$.\n",
    "- `n_epoch`: số nguyên cho biết số lượng epoch đã được thực hiện (một epoch ứng với một lần duyệt qua tập dữ liệu huấn luyện), ta output ra giá trị này vì đề bài có hỏi.\n",
    "\n",
    "<font color=blue>Quá trình thực hiện</font>\n",
    "\n",
    "Ta sẽ tìm `w` bằng cách sử dụng thuật toán SGD (kích thước minibatch bằng 1) để cực tiểu hóa $E_{in}(\\mathbf{w})$. Cụ thể các bước như sau:\n",
    "- Cho `learning_rate` của SGD bằng 0.01 (theo đề bài).\n",
    "- Khởi tạo `w` là mảng Numpy có kích thước $(d+1)\\times1$, trong đó các phần tử có giá trị bằng 0 (gợi ý: bạn có thể dùng hàm `np.zeros`).\n",
    "- Khởi tạo `n_epochs` bằng 0.\n",
    "- Lặp (mỗi vòng lặp ứng với một epoch):\n",
    "    - Trước khi duyệt qua tập dữ liệu huấn luyện và cập nhật mảng `w` thì ta lưu lại nội dung mảng `w` hiện tại vào `previous_w`. Lưu ý: bạn phải dùng hàm `np.copy` để lưu lại nội dung của `w`, bạn xem thêm ở ví dụ trong [document](https://www.numpy.org/devdocs/reference/generated/numpy.copy.html?highlight=copy#numpy.copy).\n",
    "    - Tạo `rand_idxs` là mảng Numpy có kích thước $N$, chứa các giá trị chỉ số $0, 1, ..., N-1$ nhưng được xáo trộn ngẫu nhiên (gợi ý: bạn có thể dùng hàm `np.random.permutation(N)`).\n",
    "    - Với mỗi chỉ số `idx` trong mảng các chỉ số ngẫu nhiên `rand_idxs`:\n",
    "        - Lấy ra véc-tơ input `x` (mảng Numpy, kích thước $(d+1)\\times1$) và giá trị output `y` tương ứng (con số) từ mảng `X` và `Y` dựa vào chỉ số `idx`.\n",
    "        - Tính `gradient` (mảng Numpy, kích thước $(d+1)\\times1$) từ `x`, `y`, `w` theo công thức ở slide 23, lecture 9 - the linear model II. Tuy nhiên, công thức này là tính gradient trung bình trên toàn bộ tập dữ liệu huấn luyện, còn ở đây ta chỉ tính gradient tại một mẫu (`x`, `y`).\n",
    "        - Cập nhật mảng `w` dựa vào `learning_rate` và `gradient`.\n",
    "    - Cập nhật `n_epochs`.\n",
    "    - Kiểm tra điều kiện dừng dựa vào `w` và `previous_w` (xem đề bài). *Nếu thỏa thì thoát ra khỏi vòng lặp!*\n",
    "- `return w, n_epochs`.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pdEPbsuMUW5p"
   },
   "source": [
    "**Test hàm huấn luyện Logistic Regression**\n",
    "\n",
    "Để biết đã cài đặt đúng hàm huấn luyện Logistic Regression hay chưa thì một cách là cho in ra độ lỗi cross-entropy trên tập huấn luyện sau mỗi epoch; độ lỗi này *nhìn chung* là nên đi xuống. Ngoài ra, bạn có thể in ra thêm độ lỗi binary error trên tập huấn luyện sau mỗi epoch; mặc dù độ lỗi cross-entropy là độ lỗi mà ta trực tiếp cực tiểu hóa nhưng khi độ lỗi này đi xuống thì nói chung độ lỗi binary error cũng sẽ đi xuống."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nmTKmJ3jUW5p"
   },
   "source": [
    "**Hàm dự đoán** (hàm này bạn có thể sẽ không dùng tới trong bài này nhưng mình cũng hướng dẫn luôn cho đầy đủ)\n",
    "\n",
    "Sau khi học được `w`, bạn có thể dùng `w` này để dự đoán xác suất $y=1$ với các véc-tơ input mới. Vì hàm này cũng dễ (và chắc là không cần dùng trong bài này) nên mình sẽ viết luôn cho bạn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GeH-1c9yUW5q"
   },
   "outputs": [],
   "source": [
    "def predict_prob(X, w):\n",
    "    S = X.dot(w)\n",
    "    probs = 1 / (1 + np.exp(-S))\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "og1QRMXrUW5s"
   },
   "source": [
    "**Hàm tính độ lỗi cross entropy của `w` trên một tập dữ liệu**\n",
    "\n",
    "Bạn xem công thức ở slide 16, lecture 9 - the linear model II. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J_BUaPhoGywe",
    "toc-hr-collapsed": true
   },
   "source": [
    "## Câu 10: PLA as SGD\n",
    "\n",
    "- PLA: \n",
    "    - Với mẫu $\\left(\\mathbf{x}^{(n)}, y^{(n)}\\right)$ được phân lớp đúng thì $\\mathbf{w}$ không thay đổi.\n",
    "    - Với mẫu $\\left(\\mathbf{x}^{(n)}, y^{(n)}\\right)$ bị phân lớp sai thì cập nhật: $\\mathbf{w} \\leftarrow \\mathbf{w} + y^{(n)}\\mathbf{x}^{(n)}$.\n",
    "\n",
    "- SGD: với mỗi mẫu $\\left(\\mathbf{x}^{(n)}, y^{(n)}\\right)$ thì đều cập nhật $\\mathbf{w} \\leftarrow \\mathbf{w} - \\alpha \\times \\mathbf{\\nabla_wE_{in}}$.\n",
    "\n",
    "- Có thể xem PLA là SGD với hàm lỗi $E_{in}$ cần cực tiểu hóa là hàm nào? Ở đây, $E_{in}=\\frac{1}{N}\\sum_{n=1}^Ne_n$ với $e_n$ là độ lỗi tại một mẫu huấn luyện $\\left(\\mathbf{x}^{(n)}, y^{(n)}\\right)$. Đề bài là hỏi về công thức của $e_n$. Gợi ý: cho $\\alpha=1$."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW5-Guide.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
