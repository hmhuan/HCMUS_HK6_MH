{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huỳnh Minh Huấn - 1612858"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Câu 1: Linear Regression Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.99999999999996"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Có thể sử dụng hàm find_N() => tìm ra được lowerBound của N thỏa câu 1\n",
    "def find_N(sigma, d, val):\n",
    "    return (d + 1)/(1 - 0.008 / math.pow(sigma, 2))\n",
    "find_N(0.1, 8, 0.008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def E_Ein(N, sigma, d):\n",
    "    return math.pow(sigma, 2) * (1-(d + 1)/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 10 => Ed(Ein) = 0.001\n",
      "N = 25 => Ed(Ein) = 0.006400000000000001\n",
      "N = 100 => Ed(Ein) = 0.009100000000000002\n",
      "N = 500 => Ed(Ein) = 0.009820000000000002\n",
      "N = 1000 => Ed(Ein) = 0.009910000000000002\n"
     ]
    }
   ],
   "source": [
    "sigma = 0.1\n",
    "d = 8\n",
    "print(\"N = 10 => Ed(Ein) =\", E_Ein(10, sigma, d))\n",
    "print(\"N = 25 => Ed(Ein) =\", E_Ein(25, sigma, d))\n",
    "print(\"N = 100 => Ed(Ein) =\", E_Ein(100, sigma, d))\n",
    "print(\"N = 500 => Ed(Ein) =\", E_Ein(500, sigma, d))\n",
    "print(\"N = 1000 => Ed(Ein) =\", E_Ein(1000, sigma, d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.\n",
    "\n",
    "Ta thấy với N = 100 (giá trị nhỏ nhất), thì kỳ vọng $E_{in}\\ge0.008$\n",
    "\n",
    "**Chọn [c] 100.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Câu 2 - 3: Nonlinear Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.\n",
    "Ta có: $h(\\mathbf{x}) = sign(\\tilde{w}_0 + \\tilde{w}_1 x_1^2 + \\tilde{w}_2 x_2^2)$\n",
    "\n",
    "Khi $x_1$ siêu âm hoặc siêu dương thì $x_1^2$ sẽ dương và rất lớn, và  $\\tilde{w}_1 x_1^2$ sẽ là đại lượng quyết định dấu của tổng trong công thức ở trên. Do $x_1^2$ dương nên $\\tilde{w}_1$ sẽ quyết định dấu của $\\tilde{w}_1 x_1^2$.\n",
    "\n",
    "**Chọn [].**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.\n",
    "Sử dụng công thức về $d_{VC}$ của mô hình phân lớp tuyến tính (Perceptron) trong không gian $\\mathcal{Z}$ ở slide 4, lecture 9 - the linear model II ${d_{VC}\\leq d^*+ 1}$ với $d^*+ 1$ là số chiều của w* trong không gian $\\mathcal{Z}$ (không gian khi chuyển áp dụng non-linear transform).\n",
    "\n",
    "Ta có: d* + 1 = 15, suy ra $d_{VC} \\leq 15$.\n",
    "\n",
    "Do đó: giá trị nhỏ nhất trong các đáp án mà không nhỏ hơn $d_{VC}$ là: 15.\n",
    "\n",
    "**Chọn [c] 15.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Câu 4 - 7: Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.\n",
    "\n",
    "${\\frac{\\partial E}{\\partial u} = \\frac{\\partial(ue^v-2ve^{-u})^2}{\\partial u}}$\n",
    "\n",
    "${\\frac{\\partial E}{\\partial u} = 2(ue^v-2ve^{-u})(ue^v-2ve^{-u})'}$\n",
    "\n",
    "**Kí hiệu:** $(ue^v-2ve^{-u})' = \\frac{\\partial(ue^v-2ve^{-u})}{\\partial u}$ do đang xét đạo hàm riêng theo u nên em ghi vậy cho gọn.\n",
    "\n",
    "Ta có:\n",
    "\n",
    "- $\\frac{\\partial(ue^v)}{\\partial u} = e^v$\n",
    "- $\\frac{\\partial(-2ve^{-u})}{\\partial u} = -2*(-u)'ve^{-u} = 2ve^{-u}$\n",
    "\n",
    "Do đó: ${\\frac{\\partial E}{\\partial u} = 2(ue^v-2ve^{-u})(e^v + 2ve^{-u})}$\n",
    "\n",
    "**Chọn [e] ${2(e^v + 2ve^{-u})(ue^v-2ve^{-u})}$.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gradient(grad):\n",
    "    du = 2 * (np.exp(grad[1]) + 2*grad[1]*np.exp(-grad[0]))*(grad[0]*np.exp(grad[1])-2*grad[1]*np.exp(-grad[0]))\n",
    "    dv = 2 * (grad[0]*np.exp(grad[1])-2*grad[1]*np.exp(-grad[0])) * (grad[0]*np.exp(grad[1])-2*np.exp(-grad[0]))\n",
    "    return np.array([du, dv])\n",
    "\n",
    "def Gradient_Descent(eta, threshold):\n",
    "    point = np.array([1, 1])\n",
    "    Error = math.pow(1*np.exp(1) - 2*1*np.exp(-1), 2)\n",
    "    iterations = 0\n",
    "    while Error >= threshold:\n",
    "        iterations += 1\n",
    "        point = point - eta * Gradient(point)\n",
    "        Error = math.pow(point[0]*np.exp(point[1]) - 2*point[1]*np.exp(-point[0]), 2)\n",
    "    return iterations, point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration = 10\n",
      "Point = [0.04473629 0.02395871]\n"
     ]
    }
   ],
   "source": [
    "def main_5_6(eta, threshold):\n",
    "    #eta = 0.1\n",
    "    #threshold = 1e-14\n",
    "    iterations, point = Gradient_Descent(eta, threshold)\n",
    "    print(\"Iteration =\",iterations)\n",
    "    print(\"Point =\",point)\n",
    "main_5_6(eta = 0.1, threshold = 1e-14)\n",
    "#print(Gradient([13.69542993, 7.86079446]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.\n",
    "\n",
    "**Chọn [d] 10.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.\n",
    "\n",
    "**Chọn [e] (0.045,0.024).**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13981379199615315\n"
     ]
    }
   ],
   "source": [
    "def main_7(eta, N):\n",
    "    #eta = 0.1\n",
    "    #N = 15\n",
    "    grad = np.array([1, 1])\n",
    "    for i in range(N):\n",
    "        du = 2 * (np.exp(grad[1]) + 2*grad[1]*np.exp(-grad[0]))*(grad[0]*np.exp(grad[1])-2*grad[1]*np.exp(-grad[0]))\n",
    "        grad = grad - eta * np.array([du, 0])\n",
    "        dv = 2 * (grad[0]*np.exp(grad[1])-2*grad[1]*np.exp(-grad[0])) * (grad[0]*np.exp(grad[1])-2*np.exp(-grad[0]))\n",
    "        grad = grad - eta * np.array([0, dv])\n",
    "    Error = math.pow(grad[0]*np.exp(grad[1]) - 2*grad[1]*np.exp(-grad[0]), 2)\n",
    "    print(Error)\n",
    "main_7(eta = 0.1, N = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.\n",
    "\n",
    "**Chọn [a] $10^{-1}$.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Câu 8 - 9: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hàm phát sinh ra `target_w`, véc-tơ tham số của $f$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_target_w():\n",
    "    \"\"\"\n",
    "    Generates target_w from two random, uniformly distributed points in [-1, 1] x [-1, 1].\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    target_w : numpy array, shape (3, 1) \n",
    "        The vector of parameters of f.\n",
    "    \"\"\"\n",
    "    # Generate two points from a uniform distribution over [-1, 1]x[-1, 1]\n",
    "    p1 = np.random.uniform(-1, 1, 2)\n",
    "    p2 = np.random.uniform(-1, 1, 2)\n",
    "    # Compute the target W from these two points\n",
    "    target_w = np.array([p1[1]*p2[0] - p1[0]*p2[1], p2[1] - p1[1], p1[0] - p2[0]]).reshape((-1, 1))\n",
    "    \n",
    "    return target_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hàm phát sinh ra tập dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(N, target_w):\n",
    "    \"\"\"\n",
    "    Generates a data set by generating random inputs and then using target_w to generate the \n",
    "    corresponding outputs.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N : int\n",
    "        The number of examples.\n",
    "    target_w : numpy array, shape (3, 1) \n",
    "        The vector of parameters of f.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X : numpy array, shape (N, 3)\n",
    "        The matrix of input vectors (each row corresponds to an input vector); the first column of \n",
    "        this matrix is all ones.\n",
    "    Y : numpy array, shape (N, 1)\n",
    "        The vector of outputs.        \n",
    "    \"\"\"\n",
    "    bad_data = True # `bad_data = True` means: data contain points on the target line \n",
    "                    # (this rarely happens, but just to be careful)\n",
    "                    # -> y's of these points = 0 (with np.sign); \n",
    "                    #    we don't want this (y's of data must be -1 or 1)\n",
    "                    # -> re-generate data until `bad_data = False`\n",
    "    \n",
    "    while bad_data == True:\n",
    "        X = np.random.uniform(-1, 1, (N, 2))\n",
    "        X = np.hstack((np.ones((N, 1)), X)) # Add 'ones' column\n",
    "        Y = np.sign(np.dot(X, target_w))\n",
    "        if (0 not in Y): # Good data\n",
    "            bad_data = False\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(x, y, w):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(X, Y, lr = 0.01):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    N, sizeW = X.shape\n",
    "    w = np.zeros([sizeW, 1])\n",
    "    n_epochs = 0\n",
    "    while True:\n",
    "        pre_w = np.copy(w)\n",
    "        rand_idx = np.random.permutation(N)\n",
    "        for id in rand_idx:\n",
    "            # do something\n",
    "            gradient = (np.multiply(-Y[id],X[id])/(1 + np.exp(Y[id]*np.dot(pre_w.T, X[id])))).reshape(3, 1)\n",
    "            w = w - lr*gradient\n",
    "        n_epochs += 1\n",
    "        #print(n_epochs)\n",
    "        # check conditions \n",
    "        #print(pre_w)\n",
    "        #print(w)\n",
    "        #print(np.sum(np.abs(pre_w - w)))\n",
    "        if np.linalg.norm(pre_w - w) < 0.01:\n",
    "            break\n",
    "    return w.reshape(3), n_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "0.10277519033249741\n",
      "331.23\n",
      "Wall time: 1min 42s\n"
     ]
    }
   ],
   "source": [
    "def main_8_9():\n",
    "    N = 100 # data training points\n",
    "    epochs = []\n",
    "    Eouts = []\n",
    "    # Repeat the experiment for 100 runs with diﬀerent targets and take the average.\n",
    "    for i in range(100): \n",
    "        print(i)\n",
    "        target_w = generate_target_w()\n",
    "        X, Y = generate_data(N, target_w)\n",
    "        w, n_epochs = SGD(X, Y, lr = 0.01)\n",
    "        Eout = 0\n",
    "        X_new, Y_new = generate_data(10000, target_w) # generate new data kích thước N = 10000 để tính Eout\n",
    "        # Tính Eout theo công thức cross entropy với new Data\n",
    "        for j in range(10000):\n",
    "            Eout += np.log(1 + np.exp(-Y_new[j]*np.dot(w.T, X_new[j])))\n",
    "        Eouts.append(Eout / 10000)\n",
    "        epochs.append(n_epochs)\n",
    "    print(np.mean(Eouts))\n",
    "    print(np.mean(epochs))\n",
    "%time main_8_9()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3.7416573867739413\n",
      "6\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[-1],[2],[-3]])\n",
    "print(a.shape[1])\n",
    "u,v = a.shape\n",
    "#print(u, v)\n",
    "#b = np.zeros([a.shape[0], 1])\n",
    "#print(b)\n",
    "print(np.linalg.norm(a))\n",
    "print(np.sum(np.abs(a)))\n",
    "print(np.linalg.norm([3, 4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.\n",
    "\n",
    "**Chọn [d] 0.100.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.\n",
    "\n",
    "\n",
    "\n",
    "**Chọn [a] 350.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Câu 10: PLA vs SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.\n",
    "- PLA: \n",
    "    - Với mẫu $\\left(\\mathbf{x}^{(n)}, y^{(n)}\\right)$ được phân lớp đúng thì $\\mathbf{w}$ không thay đổi.\n",
    "    - Với mẫu $\\left(\\mathbf{x}^{(n)}, y^{(n)}\\right)$ bị phân lớp sai thì cập nhật: $\\mathbf{w} \\leftarrow \\mathbf{w} + y^{(n)}\\mathbf{x}^{(n)}$.\n",
    "\n",
    "- SGD: với mỗi mẫu $\\left(\\mathbf{x}^{(n)}, y^{(n)}\\right)$ thì đều cập nhật $\\mathbf{w} \\leftarrow \\mathbf{w} - \\alpha \\times \\mathbf{\\nabla_wE_{in}}$.\n",
    "\n",
    "Xét $\\alpha=1$\n",
    "\n",
    "**Chọn [e] $e_n(w)=-min(0,y_nw^Tx_n)$.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
