{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bài tập 1\n",
    "\n",
    "## Huỳnh Minh Huấn - 1612858\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.\n",
    "\n",
    "- (i) một hệ thống phân loại các đồng xu cho máy bán hàng tự động. Các developers có được các thông số kỹ thuật tiền xu chính xác từ U.S. Mint và phái sinh ra 1 mô hình thống kê về kích thước, khối lượng và mệnh giá mà máy bán có thể dùng để phân biệt các loại tiền. Đây không phải là học, vì đã có mô hình thống kê nhằm phân loại sẵn các coin, máy chỉ tiến hành kiểm tra từ tập thống kê đã có. Việc học là phải từ kiến thức học áp dụng cho những cái mới.\n",
    "- (ii) Đây là học có giám sát. Vì ta có dữ liệu đầu vào với các nhãn được gắn (Output tương ứng).\n",
    "- (iii) Đây là học tăng cường. Vì máy được phát triển để học thông qua các sự kiện thua sau khi máy thực hiện trước đó.\n",
    "\n",
    "**Chọn [d] (i) Not learning, (ii) Supervised Learning, (iii) Reinforcement Learning.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.\n",
    "- (i) vấn đề không phù hợp với học máy (không cần dùng đến học máy) đã có các thuật toán xác định số nguyên tố.\n",
    "- (ii) Cần sử dụng học máy để dự đoán các trường hợp tiềm ẩn gian lận phí thẻ tín dụng.\n",
    "- (iii) Có công thức tính thời gian vật rơi nên không phải là vấn đề cần sử dụng học máy.\n",
    "- (iv) bài toán cần sử dụng học máy để rút ra dự đoán nhằm hỗ trợ điều tiết giao thông.\n",
    "\n",
    "**Chọn [a] (ii) và (iv).**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.\n",
    "Gọi A là biến cố bốc được túi chứa 2 bi đen P(A) = 1/2.\n",
    "\n",
    "Gọi B là biến cố bốc được bi đen ở lần thứ nhất: P(B) = 3/4. \n",
    "(Vì có 3 trong 4 TH bóc được bi đen đầu tiên: đen1(túi 1), đen2(túi 1),đen3(túi 2), w(túi 2).\n",
    "\n",
    "Xác suất để vừa bốc được túi chứa 2 bi đen và bóc được bi đen đầu tiên là: P(AB) = 1/2\n",
    "\n",
    "Xác suất để bóc viên bi thứ 2 là đen là xác suất có điều kiện của biến cố A với điều kiện B:\n",
    "$P(A|B) = \\frac{P(AB)}{P(B)} = \\frac{\\frac{1}{2}}{\\frac{3}{4}} = \\frac{2}{3}$\n",
    "\n",
    "**Chọn [d] $\\frac{2}{3}$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.\n",
    "Xác suất bóc trúng bi màu đỏ là 0.55 => xác suất bóc được bi xanh là (1 - 0.55) = 0.45\n",
    "\n",
    "Với 1 lần lấy mẫu, xác suất để v = 0 (hay không có bi màu đỏ) là: $0.45^{10}=3.405062892*10^{-4}$\n",
    "\n",
    "**Chọn [b] $3.405*10^{-4}$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.\n",
    "Gọi A là biến cố để trong mẫu 10 bi có $\\nu = 0$, B là biến cố trong tập 1000 mẫu không có mẫu nào không có bi đỏ ($\\nu = 0$).\n",
    "\n",
    "+ P(A) = $0.45^{10}$ = $3.405*10^{-4}$ (tính từ câu 4).\n",
    "+ Xác suất để có ít nhất 1 bi màu đỏ trong mẫu ($\\nu \\ne 0$) là: $P(-A) = 1 - P(A)$.\n",
    "+ Xác suất trong **1000 mẫu độc lập** không có mẫu nào **không có bi đỏ** ($\\nu = 0$) là: $P(B) = P(-A)^{1000}$\n",
    "+ -B là biến cố ngược của biến cố B là biến cố để có ít nhất một mẫu không có bi đỏ: $P(-B) = 1 - P(B) = 1 - P(-A)^{1000} = 1 - (1 - P(A))^{1000} = 1 - (1 - 0.45^{10})^{1000} = 0.2886311978..$\n",
    "\n",
    "**Chọn [c] 0.289.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.\n",
    "Xét 3 x đó là: 111, 110, 101\n",
    "ta có, 8 possible target function (tf) là (1 1 1), (1 1 0), (1 0 1), (1 0 0), (0 1 1), (0 1 0), (0 0 1), (0 0 0) \n",
    "+ Câu a, hypothesis g trả về 1 cho cả 3 points (1 1 1). Có 1 tf trả về 1 cho cả 3 points, 3 tf trả về 1 cho 2 points, 3 tf trả về 1 cho 1 points và 1 tf trả về 1 cho 0 points, Score = 1 * 3 + 3 * 2 + 3 * 1 + 1 * 0 = 12.\n",
    "+ Câu b, hypothesis g trả về 0 cho cả 3 points. Có 1 tf trả về 0 cho cả 3 points, 3 tf trả về 0 cho 2 points, 3 tf trả về 0 cho 1 points và 1 tf trả về 0 cho 0 points. Score = 1 * 3 + 3 * 2 + 3 * 1 + 1 * 0 = 12.\n",
    "+ Câu c, hypothesis g là XOR function (1 0 0). Có 1 tf trả về giống cả 3 points, 3 tf trả về giống 2 points, 3 tf trả về giống 1 points và 1 tf trả về giống 0 points. Score = 1 * 3 + 3 * 2 + 3 * 1 + 1 * 0 = 12.\n",
    "+ Câu d, hypothesis g là opposite of XOR function (0 1 1). Có 1 tf trả về giống cả 3 points, 3 tf trả về giống 2 points, 3 tf trả về giống 1 points và 1 tf trả về giống 0 points. Score = 1 * 3 + 3 * 2 + 3 * 1 + 1 * 0 = 12.\n",
    "\n",
    "Vậy điểm của cả 4 hypothesis là như nhau\n",
    "\n",
    "**Chọn [e] They are all equivalent (equal scores for g in [a] through [d]).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - 10.\n",
    "### Import các thư viện cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_target_w():\n",
    "    \"\"\"\n",
    "    Generates target_w from two random, uniformly distributed points in [-1, 1] x [-1, 1].\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    target_w : numpy array, shape (3, 1) \n",
    "        The vector of parameters of f.\n",
    "    \"\"\"\n",
    "    # Generate two points from a uniform distribution over [-1, 1]x[-1, 1]\n",
    "    p1 = np.random.uniform(-1, 1, 2)\n",
    "    p2 = np.random.uniform(-1, 1, 2)\n",
    "    # Compute the target W from these two points\n",
    "    target_w = np.array([p1[1]*p2[0] - p1[0]*p2[1], p2[1] - p1[1], p1[0] - p2[0]]).reshape((-1, 1))\n",
    "    \n",
    "    return target_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hàm phát sinh tập dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(N, target_w):\n",
    "    \"\"\"\n",
    "    Generates a data set by generating random inputs and then using target_w to generate the \n",
    "    corresponding outputs.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N : int\n",
    "        The number of examples.\n",
    "    target_w : numpy array, shape (3, 1) \n",
    "        The vector of parameters of f.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X : numpy array, shape (N, 3)\n",
    "        The matrix of input vectors (each row corresponds to an input vector); the first column of \n",
    "        this matrix is all ones.\n",
    "    Y : numpy array, shape (N, 1)\n",
    "        The vector of outputs.        \n",
    "    \"\"\"\n",
    "    bad_data = True # `bad_data = True` means: data contain points on the target line \n",
    "                    # (this rarely happens, but just to be careful)\n",
    "                    # -> y's of these points = 0 (with np.sign); \n",
    "                    #    we don't want this (y's of data must be -1 or 1)\n",
    "                    # -> re-generate data until `bad_data = False`\n",
    "    \n",
    "    while bad_data == True:\n",
    "        X = np.random.uniform(-1, 1, (N, 2))\n",
    "        X = np.hstack((np.ones((N, 1)), X)) # Add 'ones' column\n",
    "        Y = np.sign(np.dot(X, target_w))\n",
    "        if (0 not in Y): # Good data\n",
    "            bad_data = False\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hàm chạy PLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_PLA(X, Y):\n",
    "    \"\"\"\n",
    "    Runs PLA.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : numpy array, shape (N, 3)\n",
    "        The matrix of input vectors (each row corresponds to an input vector); the first column of \n",
    "        this matrix is all ones.\n",
    "    Y : numpy array, shape (N, 1)\n",
    "        The vector of outputs.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    w : numpy array, shape (3, 1) \n",
    "        The vector of parameters of g.\n",
    "    num_iterations : int\n",
    "        The number of iterations PLA takes to converge.\n",
    "    \"\"\"\n",
    "    w = np.zeros((X.shape[1], 1)) # Init w\n",
    "    iteration = 0\n",
    "    \n",
    "    # TODO\n",
    "    N = X.shape[0] \n",
    "    Y1 = np.sign(np.dot(X, w)) #(Nx1)\n",
    "    iteration += 1 #Cong truoc 1 lan vi da tinh o tren\n",
    "    while(np.array_equal(Y1, Y) == False): #So sanh de kiem tra Y1 va Y\n",
    "        for i in range(N): #Lap de tim vi tri i Y1 khac Y\n",
    "            if (Y[i][0] != Y1[i][0]):\n",
    "                w = np.add(w, np.dot(Y[i][0], X[i]).reshape(3, 1)) #Tinh lai w\n",
    "                break\n",
    "        Y1 = np.sign(np.dot(X, w))\n",
    "        iteration += 1\n",
    "\n",
    "    return w, iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hàm main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(N):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    N : int\n",
    "        The number of training examples.\n",
    "    \"\"\"\n",
    "    num_runs = 1000\n",
    "    avg_num_iterations = 0.0 # The average number of iterations PLA takes to converge\n",
    "    avg_test_err = 0.0 # The average test error of g - the final hypothesis picked by PLA\n",
    "    \n",
    "    for r in range(num_runs):\n",
    "        # Generate target_w\n",
    "        target_w = generate_target_w()\n",
    "        \n",
    "        # Generate training set\n",
    "        X, Y = generate_data(N, target_w)\n",
    "        \n",
    "        # Run PLA to pick g\n",
    "        w, num_iterations = run_PLA(X, Y)\n",
    "        \n",
    "        # Generate test set\n",
    "        X_test, Y_test = generate_data(10000, target_w)\n",
    "        \n",
    "        # Test g\n",
    "        test_err = np.mean(np.sign(np.dot(X_test, w)) != Y_test)\n",
    "        \n",
    "        # Update average values\n",
    "        avg_num_iterations += (num_iterations * 1.0 / num_runs)\n",
    "        avg_test_err += (test_err * 1.0 / num_runs)\n",
    "    \n",
    "    # Print results\n",
    "    print('avg_num_iterations = %f' % (avg_num_iterations))\n",
    "    print('avg_test_err = %f' % (avg_test_err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chạy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_num_iterations = 13.283000\n",
      "avg_test_err = 0.112698\n"
     ]
    }
   ],
   "source": [
    "main(N=10) # We can use `main(10)`, but `main(N=10)` is clearer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Câu 7**: ta thấy kết quả gần nhất với đáp án **[b] 15**.\n",
    "\n",
    "**Câu 8**: ta thấy kết quả gần nhất với đáp án **[c] 0.1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_num_iterations = 232.097000\n",
      "avg_test_err = 0.013406\n"
     ]
    }
   ],
   "source": [
    "main(N=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Câu 9**: ta thấy kết quả gần nhất với đáp án **[b] 100**.\n",
    "\n",
    "**Câu 10**: ta thấy kết quả gần nhất với đáp án **[b] 0.01**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
